CSE 12 Homework 3
Aaron Hurtado
A99128987
B00
4/18/14

Part 1A
1. True 
2. True
3. False
4. False
5. False
6. True
7. False
8. True
9. False 
10. False
11. True
12. True
13. True
14. True
15. False
16. True
17. False 
18. True


Part 1B
1.
Running time: O(n)
Explanation: There is a single loop that runs n/2 times. Each time the loop
runs it executes 1 instruction, so the total number of instructions
executed is n/2 + 1 + n/2(1) =  n + 1 = O(n).

2.
Running time: O(log(n))
Explanation: The loop incrementer double by 2 each time so the loop stops
relatively fast. The loop increases rapidly then plateaus as the i variable
grows faster and fastwe. This most resembles the function log(n).

3.
Running time: O(n^2)
Explanation: The outer loop is checked which is 1 operation. Then the inner
loop is executed which is 2n + 1 operations. So one complete execution is 2n +
2 operations, which happens n times plus one additional operation when the
outerloop fails. Thus we get n(2n + 1) + 1 = 2n^2 + n + 1 = O(n^2). 

4.
Running time: O(n)
Explanation: This code is made up of two individuals for loops with only one
operation in their body. Each loop has 2n + 1 operations. So the total is
2*(2n + 1) = 4n + 2 = O(n).

5.
Running time: O(n)
Explanation: The loop header runs 2n + 1 times. The body has 1 operation 2n times.
Therefore the total is 2n + 1 + 2n(1) = 4n + 1 = O(n).

6.
Running time: O(n^2)
Explanation: The loop header runs n^2 + 1 times. THe body has 1 operation n^2 times.
Thus the total is n^2 + 1 + n^2(1) = 2n^2 + 1 = O(n^2).

7.
Running time: O(n^3)
Explanation: The outerloop header runs once, then the inner loop header runs
n^2 + 1 times and the inner loop body has 1 operation n^2 times. This happens
n times. The total is n(2n^2 + 1) + 1 = 2n^3 + n + 1 = O(n^3).

8.
Running time: O(n)
Explanation: The outer loop header is checked which is 1 oepration. Then inner
loop header has 10001 operations and its body has 10000 operations and this
happens n times. Therefore the total is n(20001) + 1 = 20001n + 1 = O(n).


Part 2
1. Making a copy of the list.
Running time: big-omega(n)
Explanation: Making a copy of the list is entirely dependent on the size of
the linked list. In order to make a complete copy of the list you have to
create a copy of each individual node. Since n is the number of elements in
the linked list the minimum running time is big-omega(n).

2. Adding a value to the end of the list.
Running time: big-omega(1)
Explanation: You have a pointer to the tail node in the list, so adding an
element involves creating a new node (which does not depend on the size of the
list), setting the links in the new node, and changing the the tail refernces.
This is about 10 operations, and 10 = big-omega(1).

3. Removing the first value from the list.
Running time: big-omega(1)
Explanation: You have a pointer to the head of the list so all you have to do
is remove the first node in the list and then fix the refernces for the new
first value. This does not depend on the size of the list and the function has
about 5 operations and 5 = big-omega(1).

4. Removing the last value from the list.
Running time: big-omega(1)
Explanation: You have a pointer to the tail of the list so all you have to do
is remove the last node in the list and then fix the refernces for the new
last value. This does not depend on the size of the list and the function has
about 5 operations and 5 = big-omega(1).

5. Determinning whether the list contains some value V.
Running time: big-omega(n)
Explanation: To determine whether a linked list contains a value V for the
worst case scenario is where you have to check every single node in the list.
Thus the required running time depends on the size of the list which is n.
Therefore this operation has big-omega(n).


Part 3
Question 1:
A.
wc medium-wordlist.txt 
 119805  119805 1146872 medium-wordlist.txt
wc is the unix command. The second 119805 of the output is the wordcount.

B.
main()
    // makes sure that a dictionary and a document are inputed as arguments
    usage (if args < 2)
    doLoops(MyLinkedList, wordlist, input file, loop bounds and steps)
        // checks if words in document are in dictionary
    	doWork(storage, wordlist, document, numwords, reps)
    	    // reads inputed dictionary and is called in doWork
    	    readDictionary(items, wordlist)
            trimPunctuation(word)
	    trimPunctuation(input.next())    
    doLoops(MRUList, wordlist, input file, loop bounds and steps)
        // checks if words in document are in dictionary
    	doWork(storage, wordlist, document, numwords, reps)
            // reads inputed dictionary and is called in doWork
            readDictionary(items, wordlist)
            trimPunctuation(word)
	    trimPunctuation(input.next())

C.
The class hashSet is defined in the Java Collections Framework. It implements
the Iterable<E> and Collection<E> interfaces.

D.
No, because the text in the document is essentially random and not in any
particular order. Thus having the dictionary alphabetically sorted will not
have a significant impact. Overall this makes no impactful difference in the
overall performance.


Question 2:

$ java CollectionTimer small-wordlist.txt pride-and-prejudice.txt
Wordlist: small-wordlist.txt  Document: pride-and-prejudice.txt
Class: MyLinkedList
=======================================
  1:    5000 words in     225 milliseconds
  2:   10000 words in     515 milliseconds
  3:   15000 words in     646 milliseconds
  4:   20000 words in     993 milliseconds
  5:   25000 words in    1215 milliseconds

Wordlist: small-wordlist.txt  Document: pride-and-prejudice.txt
Class: MRUList
=======================================
  1:    5000 words in     106 milliseconds
  2:   10000 words in     213 milliseconds
  3:   15000 words in     303 milliseconds
  4:   20000 words in     424 milliseconds
  5:   25000 words in     552 milliseconds


Question 3:

Yes I would expect as the size of m doubles for the worst case running time to
also double. This is a result of the function being linear in terms of the
number of words to be read in. Thus as m increases so does the running time
(because it is a linear function).


Question 4:

$ java CollectionTimer medium-wordlist.txt pride-and-prejudice.txt
Wordlist: medium-wordlist.txt  Document: pride-and-prejudice.txt
Class: MyLinkedList
=======================================
  1:    5000 words in    7022 milliseconds
  2:   10000 words in   15981 milliseconds
  3:   15000 words in   19412 milliseconds
  4:   20000 words in   46022 milliseconds
  5:   25000 words in   54151 milliseconds

Wordlist: medium-wordlist.txt  Document: pride-and-prejudice.txt
Class: MRUList
=======================================
  1:    5000 words in    3318 milliseconds
  2:   10000 words in    3187 milliseconds
  3:   15000 words in    8684 milliseconds
  4:   20000 words in   10894 milliseconds
  5:   25000 words in    7068 milliseconds

I would expect the performance to be about 10 times slower. Since the function
is linear, as the size of either the dictionary or document increases so will
the running time of the perfomance. From my experiment the MyLinkedList
became much slower compared to the MRUList. I think this is because since the
MRUList moves recently used words to the beginning of the list, this creates a
slight performance boost that is noticable with larger inputs.


Question 5:

$ java CollectionTimer pride-and-prejudice.txt pride-
and-prejudice.txt
Wordlist: pride-and-prejudice.txt  Document: pride-and-prejudice.txt
Class: MyLinkedList
=======================================
  1:    5000 words in      56 milliseconds
  2:   10000 words in     156 milliseconds
  3:   15000 words in     343 milliseconds
  4:   20000 words in     472 milliseconds
  5:   25000 words in     899 milliseconds

Wordlist: pride-and-prejudice.txt  Document: pride-and-prejudice.txt
Class: MRUList
=======================================
  1:    5000 words in    1419 milliseconds
  2:   10000 words in    3431 milliseconds
  3:   15000 words in    4022 milliseconds
  4:   20000 words in    5603 milliseconds
  5:   25000 words in    6693 milliseconds

MyLinkedList runs much faster compared to MRUList. This is because MRUList
moves words to the front of the list and this doesn't help in this scenario
because words are usually not repeated. Where as MyLinkedList the dictionary
and the text it is checking are in the exact same order so checking is extremely fast.
